# Sentence Transformers
> Sentence Embeddings with BERT

There are many achievements in the Natural Language field for English or even other languages, but in the case of Persian, as you can see, there are not many. 
Perhaps the lack of data resources, non-disclosure of sources by research groups, and decentralized research communities are the main reasons for Persian's current state. 

Of course, it should be noted that some of the research groups concern about this matter and share their results, thoughts, and resources with others, but still, we need more.

NLI (known as recognizing textual entailment) resources for Persian are vital for every semantic, extraction, and inference system. 
I was so excited when [FarsTail](https://github.com/dml-qom/FarsTail), as the first NLI dataset for Persian, was released. 
I used this dataset to train a Sentence-Transformer model (using [ParsBERT](https://github.com/hooshvare/parsbert)) as a basis for other applications like Semantic Search, Clustering, Information Extraction, Summarization, Topic Modeling, and some others. 
However, the model could be achieved remarkable results on recognizing entailment (81.71%) in contrast to what they mentioned in their [paper](https://arxiv.org/abs/2009.08820) (78.13%), still not adequate for NLI applications.

I dug in the official paper of Sentence-Transformer [Reimers and Gurevych, 2019](https://arxiv.org/abs/1908.10084). 
I found that it used the Wikipedia-Triplet-Sections, introduced by [Dor et al., 2018](https://www.aclweb.org/anthology/P18-2009/), to train the SBERT for recognizing entailment task. 
[Dor et al., 2018](https://www.aclweb.org/anthology/P18-2009/), presume that sentences in the same section are thematically closer than sentences in different sections. 
They presented the anchor (<img src="https://render.githubusercontent.com/render/math?math=a">) and the positive (<img src="https://render.githubusercontent.com/render/math?math=p">) example from the same section, while the negative example (<img src="https://render.githubusercontent.com/render/math?math=n">) comes from a separate section of the same article.
They designated the following steps to generate this sentences-triplet dataset (In each rule, I would specify whether to use the principal or not):

1. Exploit Wikipedia partitioning into sections and paragraphs, using OpenNLP for sentence extraction.
2. Apply the following rules and filters to reduce noise and to create a high-quality dataset, â€˜triplets-senâ€™:
    1. The maximal distance between the intra-section sentences is limited to three paragraphs. (Change this rule into two terms, inner and outer part. The sentences from the outer part (<img src="https://render.githubusercontent.com/render/math?math== n">) must be with a distance of at least two sections. The sentences from the inner part (<img src="https://render.githubusercontent.com/render/math?math== a, p">) must be a distance of at most two paragraphs.)
    2. Sentences with less than 5 or more than 50 tokens are filtered out. (Change this relation into 10 < length of word tokens < 130.)
    3. The first and the â€Backgroundâ€ sections are removed due to their general nature. (Do the same.)
    4. The following sections are removed: "External links", "Further reading", "References", "See also", "Notes","Citations" and "Authored books". These sections usually list a set of items rather than discuss a specific subtopic of the articleâ€™s title. (Add a few more filters: Ù…Ø­ØªÙˆÛŒØ§Øª-Ù¾Ø§Ù†ÙˆÛŒØ³-Ù…Ù†Ø§Ø¨Ø¹-Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù¾Ø§Ù†ÙˆÛŒØ³-Ø¬Ø³ØªØ§Ø±Ù‡Ø§ÛŒ ÙˆØ§Ø¨Ø³ØªÙ‡-Ù¾ÛŒÙˆÙ†Ø¯ Ø¨Ù‡ Ø¨ÛŒØ±ÙˆÙ†-ÛŒØ§Ø¯Ø¯Ø§Ø´Øªâ€ŒÙ‡Ø§-ÛŒØ§Ø¯Ø¯Ø§Ø´Øªâ€Œ Ù‡Ø§-Ø¬ÙˆØ§ÛŒØ²-Ù†Ú¯Ø§Ø±Ø®Ø§Ù†Ù‡-Ø±ÙˆØ§Ø¨Ø·â€ŒØ®Ø§Ø±Ø¬ÛŒ-Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬ÛŒ-Ú©ØªØ§Ø¨â€ŒØ´Ù†Ø§Ø³ÛŒ-Ú©ØªØ§Ø¨â€Œ Ø´Ù†Ø§Ø³ÛŒ-ÙÛŒÙ„Ù…â€ŒØ´Ù†Ø§Ø³ÛŒ-ÙÛŒÙ„Ù… â€ŒØ´Ù†Ø§Ø³ÛŒ-Ø¯Ø³Øªâ€ŒØ§Ù†Ø¯Ø±Ú©Ø§Ø±Ø§Ù†-Ø¯Ø³Øªâ€ŒØ§Ù†Ø¯Ø± Ú©Ø§Ø±Ø§Ù†-Ø¯Ø³Øªâ€Œ Ø§Ù†Ø¯Ø± Ú©Ø§Ø±Ø§Ù†-ÙØ±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ú¯Ø²ÛŒØ¯Ù‡Ù” Ø¢Ù„Ø¨ÙˆÙ…-ÙØ±ÙˆØ´â€Œ Ù‡Ø§ÛŒ Ø¨Ø±Ú¯Ø²ÛŒØ¯Ù‡Ù” Ø¢Ù„Ø¨ÙˆÙ…-ÙØ±ÙˆØ´â€Œ Ù‡Ø§ÛŒ Ø¨Ø±Ú¯Ø²ÛŒØ¯Ù‡ Ø¢Ù„Ø¨ÙˆÙ…-Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ÙØ±ÙˆØ´-Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡Ø§ÛŒ ÙØ±ÙˆØ´-ÙÙ‡Ø±Ø³Øª Ø¢Ù‡Ù†Ú¯â€ŒÙ‡Ø§-ÙÙ‡Ø±Ø³Øª Ø¢Ù‡Ù†Ú¯â€Œ Ù‡Ø§-Ø§Ø¹Ø¶Ø§-ØªØ±Ø§Ù†Ù‡â€ŒØ´Ù†Ø§Ø³ÛŒ-ØªØ±Ø§Ù†Ù‡â€Œ Ø´Ù†Ø§Ø³ÛŒ-Ù†Ú¯Ø§Ø±Ø®Ø§Ù†Ù‡-Ø¨Ø§Ø²ÛŒÚ¯Ø±Ø§Ù†-Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡-Ù¾Ø±ÙˆÚ˜Ù‡â€Œ Ù‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡)
    5. Only articles with at least five remaining sections are considered to focus on articles with rich enough content. (Skip this rule.)
 
[Reimers and Gurevych, 2019](https://arxiv.org/abs/1908.10084) use the dataset with a Triplet Objective to train the SBERT.

<p align="center">
    <img src="https://render.githubusercontent.com/render/math?math=\max%20\left(\left\|s_{a}-s_{p}\right\|-\left\|s_{a}-s_{n}\right\|+\epsilon,%200\right)" alt="">
    <br>
    <em>Eq 1: Triplet Objective Function, try to minimize the above loss function.</em>
</p>

**Tips:** SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed-sized sentence embedding. They experimented with three pooling strategies:

- Using the production of the CLS-token.
- Computing the mean of all output vectors (Mean-Strategy).
- Computing a max-over-time of the output vectors (Max-Strategy).

In this case,  I use ***Mean-Strategy***.

In the following parts, I would show you how to do these rules step by step. 
Before going any further, I noticed that some of the Wikipedia articles are entirely English or other languages than Persian, like "Ø§Ù_Ø´Ø§Ø±Ù¾", "Ø³ÛŒ_Ø´Ø§Ø±Ù¾", and some others which must be removed. 
So, I add a bunch of preprocessing steps into the above rules.

## Preprocessing Rules

The preprocessing steps are as follow:

1. Remove or filter some special characters which are used more by Wikipedia users or Persian users (_, Â«, [[, [ [, separated domains, Ù‡ ÛŒ, Ù‡Ù”, Ø£).
2. Remove user tag, hashtag, and underscore but keep the text.
3. Remove emojis in every mode.
4. Preprocess and normalize text at the low level using the clean-text and hazm packages.
    1. Fix Unicode.
    2. Filter emails, URLs, numbers, phone numbers, digits, currency symbols, and punctuations.
    3. Make text lower case.
    4. Clean HTML tags.
    5. Normalize text into Persian characters.
5. Remove weird Unicode.
6. Remove redundant spaces (keep the newlines).
7. Remove articles which have more non-Persian characters (with a threshold of 0.7)

## In Action
A Wikipedia article sample is shown in Fig 1. 
The red boxes were removed due to the Dor et al., 2018 rules.  

<p align="center">
    <a href="assets/sample-wiki.png"><img src="assets/sample-wiki.png" height="500"/></a>
    <br>
    <em>Fig 1: Wikipedia Article Sample "Ø¬Ø§Ù† Ù…ÛŒÙ„ÛŒÙ†Ú¯ØªÙˆÙ† Ø³ÛŒÙ†Ú¯"</em>
</p>


The following figure (Fig 2) shows the article after passing the mutated Dor et al., 2018 rules and preprocessing steps known as the Wikipedia-Section-Paragraphs.

<p align="center">
    <a href="assets/P-1.png"><img src="assets/P-1.png"/></a>
    <br>
    <em>Fig 2: Wikipedia-Section-Paragraphs.</em>
</p>

Then, we need to convert the section-paragraphs into section-sentences in order to have a recognizing entailment dataset. The following steps need to replace with some of the rules defined by Dor et al., 2018.

1. Remove these trivial sections (Ù…Ø­ØªÙˆÛŒØ§Øª-Ù¾Ø§Ù†ÙˆÛŒØ³-Ù…Ù†Ø§Ø¨Ø¹-Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù¾Ø§Ù†ÙˆÛŒØ³-Ø¬Ø³ØªØ§Ø±Ù‡Ø§ÛŒ ÙˆØ§Ø¨Ø³ØªÙ‡-Ù¾ÛŒÙˆÙ†Ø¯ Ø¨Ù‡ Ø¨ÛŒØ±ÙˆÙ†-ÛŒØ§Ø¯Ø¯Ø§Ø´Øªâ€ŒÙ‡Ø§-ÛŒØ§Ø¯Ø¯Ø§Ø´Øªâ€Œ Ù‡Ø§-Ø¬ÙˆØ§ÛŒØ²-Ù†Ú¯Ø§Ø±Ø®Ø§Ù†Ù‡-Ø±ÙˆØ§Ø¨Ø·â€ŒØ®Ø§Ø±Ø¬ÛŒ-Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬ÛŒ-Ú©ØªØ§Ø¨â€ŒØ´Ù†Ø§Ø³ÛŒ-Ú©ØªØ§Ø¨â€Œ Ø´Ù†Ø§Ø³ÛŒ-ÙÛŒÙ„Ù…â€ŒØ´Ù†Ø§Ø³ÛŒ-ÙÛŒÙ„Ù… â€ŒØ´Ù†Ø§Ø³ÛŒ-Ø¯Ø³Øªâ€ŒØ§Ù†Ø¯Ø±Ú©Ø§Ø±Ø§Ù†-Ø¯Ø³Øªâ€ŒØ§Ù†Ø¯Ø± Ú©Ø§Ø±Ø§Ù†-Ø¯Ø³Øªâ€Œ Ø§Ù†Ø¯Ø± Ú©Ø§Ø±Ø§Ù†-ÙØ±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ú¯Ø²ÛŒØ¯Ù‡Ù” Ø¢Ù„Ø¨ÙˆÙ…-ÙØ±ÙˆØ´â€Œ Ù‡Ø§ÛŒ Ø¨Ø±Ú¯Ø²ÛŒØ¯Ù‡Ù” Ø¢Ù„Ø¨ÙˆÙ…-ÙØ±ÙˆØ´â€Œ Ù‡Ø§ÛŒ Ø¨Ø±Ú¯Ø²ÛŒØ¯Ù‡ Ø¢Ù„Ø¨ÙˆÙ…-Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ÙØ±ÙˆØ´-Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡Ø§ÛŒ ÙØ±ÙˆØ´-ÙÙ‡Ø±Ø³Øª Ø¢Ù‡Ù†Ú¯â€ŒÙ‡Ø§-ÙÙ‡Ø±Ø³Øª Ø¢Ù‡Ù†Ú¯â€Œ Ù‡Ø§-Ø§Ø¹Ø¶Ø§-ØªØ±Ø§Ù†Ù‡â€ŒØ´Ù†Ø§Ø³ÛŒ-ØªØ±Ø§Ù†Ù‡â€Œ Ø´Ù†Ø§Ø³ÛŒ-Ù†Ú¯Ø§Ø±Ø®Ø§Ù†Ù‡-Ø¨Ø§Ø²ÛŒÚ¯Ø±Ø§Ù†-Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡-Ù¾Ø±ÙˆÚ˜Ù‡â€Œ Ù‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡).
2. For each remaining section, split them into paragraphs. If the length of the paragraphs is greater than two, move forward.
3. For each paragraph, tokenize text into sentences. If the length of the sentences is greater than two, move forward.
4. For each sentence in a paragraph, tokenize text into words. If the words' length is greater than 10, pick the first sentence; otherwise, merge the following sentences until the tokenized words' size be greater than 10.

The following figure (Fig 3) presents the article after passing the mutated rules known as the Wikipedia-Section-Sentences.

<p align="center">
    <a href="assets/P-2.png"><img src="assets/P-2.png"/></a>
    <br>
    <em>Fig 3: Wikipedia-Section-Sentences.</em>
</p>


Then, I compose a combination of sections in an article with a distance of at least two segments concerning their orders. Suppose that we have an article with four sections. 
The outcome of this composition shown as follow:

- **Article Sections** 

```python
sections = ['Section 1', 'Section 2', 'Section 3', 'Section 4']
```

- **Composition Sections**

```python
composition = [['Section 1', 'Section 4'], ['Section 1', 'Section 3'], ['Section 2', 'Section 4']]
```

Each pair-sections shows the order of sentence extraction. For example, the pair ['Section 1', 'Section 4'] specifies that the anchor and positive examples must be chosen from `Section 1` and the negative example from `Section 4`. Also, consider that the selected anchor and positive examples from `Section 1` should be chosen from paragraphs with a distance of at most two in that section, shown in Fig 4. 

<p align="center">
    <a href="assets/P-3.png"><img src="assets/P-3.png" /></a>
    <br>
    <em>Figure 4: Wikipedia-Triplet-Sentences.</em>
</p>

**Examples**

| Sentence1 (<img src="https://render.githubusercontent.com/render/math?math=a">)                                   	| Sentence2 (<img src="https://render.githubusercontent.com/render/math?math=p">)                                                                           	| Sentence3 (<img src="https://render.githubusercontent.com/render/math?math=n">)                                           	|
|-------------------------------------------------------------------------------------------------------------------	|-----------------------------------------------------------------------------------------------------------------------------------------------------------	|---------------------------------------------------------------------------------------------------------------------------	|
| Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§ÛŒ Ø¯ÛŒÚ¯Ø± ØŒ Ø§Ø² Ø¬Ù…Ù„Ù‡ Ù…ÙˆØ¬ Ø§ÙˆÙ„ ÙÙ…ÛŒÙ†ÛŒØ³Ù… ØŒ Ø±ÙØ±Ù… Ø§Ø®Ù„Ø§Ù‚ÛŒ Ùˆ Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ù…ÛŒØ§Ù†Ù‡ Ø±Ùˆ Ù†ÛŒØ² Ø¯Ø± ØªÙˆØ³Ø¹Ù‡ ÙˆÙ†Ú©ÙˆÙˆØ± Ù…Ø¤Ø«Ø± Ø¨ÙˆØ¯Ù†Ø¯ . 	| Ø§Ø¯ØºØ§Ù… Ù¾ÙˆÛŒÙ†Øª Ú¯Ø±ÛŒ Ùˆ ÙˆÙ†Ú©ÙˆÙˆØ± Ø¬Ù†ÙˆØ¨ÛŒ Ø¨Ù‡ Ø´Ù‡Ø± ÙˆÙ†Ú©ÙˆÙˆØ± ØŒ Ø¢Ø®Ø±ÛŒÙ† Ù…Ø±Ø²Ø¨Ù†Ø¯ÛŒ Ù‡Ø§ÛŒ Ø´Ù‡Ø±ÛŒ Ø±Ø§ Ø±Ù‚Ù… Ø²Ø¯ Ùˆ Ù…Ø¯ØªÛŒ Ø¨Ø¹Ø¯ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø³ÙˆÙ…ÛŒÙ† Ú©Ù„Ø§Ù† Ø´Ù‡Ø± Ú©Ø§Ù†Ø§Ø¯Ø§ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±Ø¯ .                     	| Ø¯Ø± Ø³Ø§Ù„ Û²Û°Û°Û¸ ØŒ Ø¯Ø± Ù…ÛŒØ§Ù† Û²Û· Ú©Ù„Ø§Ù† Ø´Ù‡Ø± Ú©Ø§Ù†Ø§Ø¯Ø§ ØŒ ÙˆÙ†Ú©ÙˆÙˆØ± Ù‡ÙØªÙ…ÛŒÙ† Ø¢Ù…Ø§Ø± Ø¬Ø±Ù… Ùˆ Ø¬Ù†Ø§ÛŒØª Ø±Ø§ Ø¯Ø§Ø´Øª Ú©Ù‡ Ø§Ø² Ø³Ø§Ù„ Û²Û°Û°Ûµ ØŒ Ø³Ù‡ Ù¾Ù„Ù‡ Ø³Ù‚ÙˆØ· Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯ . 	|
| ÛŒÚ©ÛŒ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒ Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø³ÛŒØ³ØªÙ… Ù‡Ø§ÛŒ Ù…Ø§Ù„ÛŒØ§ØªÛŒ ØŒ Ø¯Ø±ØµØ¯ Ø¨Ø§Ø± Ù…Ø§Ù„ÛŒØ§ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¯Ø±Ø¢Ù…Ø¯ ÛŒØ§ Ù…ØµØ±Ù Ø§Ø³Øª .                            	| ÛŒÚ© Ù…Ø§Ù„ÛŒØ§Øª ØµØ¹ÙˆØ¯ÛŒ ØŒ Ù…Ø§Ù„ÛŒØ§ØªÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ú¯ÙˆÙ†Ù‡ Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ Ú©Ù‡ ÙˆÙ‚ØªÛŒ Ù…Ø¨Ù„ØºÛŒ Ú©Ù‡ Ø¨Ù‡ Ø¢Ù† Ù…Ø§Ù„ÛŒØ§Øª Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒ ÛŒØ§Ø¨Ø¯ ØŒ Ù†Ø±Ø® Ù…Ø§Ù„ÛŒØ§Øª Ù…Ø¤Ø«Ø± Ù†ÛŒØ² Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒ ÛŒØ§Ø¨Ø¯ . 	| Ø§Ø¶Ø§ÙÙ‡ Ø±ÙØ§Ù‡ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡ Ø¨Ø§Ø¹Ø« ØªÙ†Ø¸ÛŒÙ… Ù…Ø§Ù„ÛŒØ§Øª Ù‡Ø§ Ø¯Ø± ØªØ±Ø§Ø² Ú©Ø±Ø¯Ù† (ÙØ±ØµØª Ù‡Ø§ Ø¯Ø±) Ø²Ù…ÛŒÙ† Ø¨Ø§Ø²ÛŒ ØªØ¬Ø§Ø±ÛŒ Ù†Ù…ÛŒ Ø´ÙˆØ¯ .                           	|

As far as this mutated method can understand the entailment and thematic, we could use a similar procedure to extract the NLI dataset, shown in Fig 5.

<p align="center">
    <a href="assets/P-4.png"><img src="assets/P-4.png" /></a>
    <br>
    <em>Figure 5: Wikipedia-NLI.</em>
</p>

**Examples**

|                                                                              Sentence1                                                                              	|                                                                                       Sentence2                                                                                      	|        Label        	|
|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------:	|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:	|:-------------------:	|
| Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø¢Ù„Ù…Ø§Ù† Ø¯Ø± Ø³Ø§Ù„ Ù‡Ø§ÛŒ Û±Û¹Û±Û¸ Ùˆ Û±Û¹Û±Û¹ Ø§Ùˆ Ø¨Ù‡ Ø¨Ø±Ù¾Ø§ÛŒÛŒ ØªØ´Ú©ÛŒÙ„Ø§Øª ÙØ±Ø§ÛŒÚ©ÙˆØ±Ù¾Ø³ Ú©Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø´Ø¨Ù‡ Ù†Ø¸Ø§Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ú©ÙˆØ¨ ØªØ­Ø±Ú©Ø§Øª Ø§Ù†Ù‚Ù„Ø§Ø¨ÛŒ Ú©Ù…ÙˆÙ†ÛŒØ³ØªÛŒ Ø¯Ø± Ø§Ø±ÙˆÙ¾Ø§ÛŒ Ù…Ø±Ú©Ø²ÛŒ Ø¨ÙˆØ¯ ØŒ Ú©Ù…Ú© Ú©Ø±Ø¯ . 	|                            Ú©Ø§Ù†Ø§Ø±ÛŒØ³ Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ú¯ Ø¯Ø± Ø§Ø±ØªØ´ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯ ØŒ Ø§ÙˆÙ„ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø¶Ùˆ ÙØ±Ø§ÛŒÚ©ÙˆØ±Ù¾Ø³ Ùˆ Ø³Ù¾Ø³ Ø¯Ø± Ù†ÛŒØ±ÙˆÛŒ Ø¯Ø±ÛŒØ§ÛŒÛŒ Ø±Ø§ÛŒØ´.Ø¯Ø± Û±Û¹Û³Û± Ø¨Ù‡ Ø¯Ø±Ø¬Ù‡ Ø³Ø±ÙˆØ§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ Ø¨ÙˆØ¯ .                           	|  <br>entailment     	|
| Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø¢Ù„Ù…Ø§Ù† Ø¯Ø± Ø³Ø§Ù„ Ù‡Ø§ÛŒ Û±Û¹Û±Û¸ Ùˆ Û±Û¹Û±Û¹ Ø§Ùˆ Ø¨Ù‡ Ø¨Ø±Ù¾Ø§ÛŒÛŒ ØªØ´Ú©ÛŒÙ„Ø§Øª ÙØ±Ø§ÛŒÚ©ÙˆØ±Ù¾Ø³ Ú©Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø´Ø¨Ù‡ Ù†Ø¸Ø§Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ú©ÙˆØ¨ ØªØ­Ø±Ú©Ø§Øª Ø§Ù†Ù‚Ù„Ø§Ø¨ÛŒ Ú©Ù…ÙˆÙ†ÛŒØ³ØªÛŒ Ø¯Ø± Ø§Ø±ÙˆÙ¾Ø§ÛŒ Ù…Ø±Ú©Ø²ÛŒ Ø¨ÙˆØ¯ ØŒ Ú©Ù…Ú© Ú©Ø±Ø¯ . 	| Ù¾Ø³Ø± Ø³Ø±Ù‡Ù†Ú¯ ÙˆØ³Ù„ ÙØ±ÛŒÛŒØªØ§Ú¯ Ù„ÙˆØ±ÛŒÙ†Ú¯ÙˆÙˆÙ† Ø¨Ù‡ Ù†Ø§Ù… Ù†ÛŒÚ©ÛŒ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§Ø±ØªØ¨Ø§Ø· Ú©Ø§Ù†Ø§Ø±ÛŒØ³ Ø¨Ø§ Ø¨Ù‡Ù… Ø®ÙˆØ±Ø¯Ù† ØªÙˆØ·Ø¦Ù‡ Ù‡ÛŒØªÙ„Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø¯Ù…Ø±Ø¨Ø§ÛŒÛŒ Ùˆ ØªØ±ÙˆØ± Ù¾Ø§Ù¾ Ù¾ÛŒÙˆØ³ Ø¯ÙˆØ§Ø²Ø¯Ù‡Ù… Ø¯Ø± Ø§ÛŒØªØ§Ù„ÛŒØ§ Ø¯Ø± Û±Û¹Û·Û² Ø¯Ø± Ù…ÙˆÙ†ÛŒØ® Ø´Ù‡Ø§Ø¯Øª Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª . 	|  <br>contradiction  	|
| Ø´Ù‡Ø± Ø´ÛŒØ±Ø§Ø² Ø¯Ø± Ø¨ÛŒÙ† Ø³Ø§Ù„ Ù‡Ø§ÛŒ Û±Û³Û´Û· ØªØ§ Û±Û³ÛµÛ· Ù…Ø­Ù„ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¬Ø´Ù† Ù‡Ù†Ø± Ø´ÛŒØ±Ø§Ø² Ø¨ÙˆØ¯ .                                                                                               	| Ø¬Ø´Ù†ÙˆØ§Ø±Ù‡ Ø§ÛŒ Ø§Ø² Ù‡Ù†Ø± Ù†Ù…Ø§ÛŒØ´ÛŒ Ùˆ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¨ÙˆØ¯ Ú©Ù‡ Ø§Ø² Ø³Ø§Ù„ Û±Û³Û´Û¶ ØªØ§ Û±Û³ÛµÛ¶ Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† ØªØ§Ø¨Ø³ØªØ§Ù† Ù‡Ø± Ø³Ø§Ù„ Ø¯Ø± Ø´Ù‡Ø± Ø´ÛŒØ±Ø§Ø² Ùˆ ØªØ®Øª Ø¬Ù…Ø´ÛŒØ¯ Ø¨Ø±Ú¯Ø²Ø§Ø± Ù…ÛŒ Ø´Ø¯ .                                                         	|  <br>entailment     	|
| Ø´Ù‡Ø± Ø´ÛŒØ±Ø§Ø² Ø¯Ø± Ø¨ÛŒÙ† Ø³Ø§Ù„ Ù‡Ø§ÛŒ Û±Û³Û´Û· ØªØ§ Û±Û³ÛµÛ· Ù…Ø­Ù„ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¬Ø´Ù† Ù‡Ù†Ø± Ø´ÛŒØ±Ø§Ø² Ø¨ÙˆØ¯ .                                                                                               	| ÙˆØ±Ø²Ø´Ú¯Ø§Ù‡ Ù¾Ø§Ø±Ø³ Ø¨Ø§ Ø¸Ø±ÙÛŒØª ÛµÛ° Ù‡Ø²Ø§Ø± ØªÙ† Ú©Ù‡ Ø¯Ø± Ø¬Ù†ÙˆØ¨ Ø´ÛŒØ±Ø§Ø² ÙˆØ§Ù‚Ø¹ Ø´Ø¯Ù‡ Ø§Ø³Øª .                                                                                                                     	|  <br>contradiction  	|


## Future Works
1. It is crucial to mention that the whole process was done on 21,515 articles due to the lack of computational resources. I believe that the model can achieve excellent results if it is trained on the entire Wikipedia articles.
2. What do you think (Let me know, in the repository issues)?  

## Dataset Information ( ğŸ˜ )

**Version 1.0.0**

- [Wikipedia Section Sentences](https://drive.google.com/uc?id=1uax1CncimQU-_kWvNigBONyplVRdi7PX)
- [Wiki Triplet](https://drive.google.com/uc?id=1-lfrhHZwleYR4s0xGkXZPXxTeF25Q4C3)
- [Wiki NLI](https://drive.google.com/uc?id=1801hoAM4hkGjFY8zUirPMPJ5hFzy7K4B)

### Wikipedia Sections Sentences

| Version 	| Examples 	| Titles 	| Sections 	|
|---------	|----------	|--------	|----------	|
| 1.0.0   	| 205,768  	| 21,515 	| 34,298   	|


### Wiki NLI

| Version 	| Train   	| Dev   	| Test  	|
|---------	|---------	|-------	|-------	|
| 1.0.0   	| 180,585 	| 5,586 	| 5,758 	|


### Wiki Triplet

| Version 	| Train   	| Dev   	| Test  	|
|---------	|---------	|-------	|-------	|
| 1.0.0   	| 126,628 	| 5,277 	| 5,497 	|

## Evaluation

The following table summarizes the scores obtained by each dataset and model.

| Model                                     	| Dataset     	| Metrics (%)                                                                     	|
|-------------------------------------------	|-------------	|---------------------------------------------------------------------------------	|
| parsbert-base-wikinli-mean-tokens         	| wikinli     	| Accuracy: 76.20                                                                 	|
| parsbert-base-wikinli                     	| wikinli     	| F1: 77.84,  Accuracy: 77.84                                                     	|
| parsbert-base-wikitriplet-mean-tokens     	| wikitriplet 	| Accuracy Cosinus: 93.33,  Accuracy Manhatten: 94.40,  Accuracy Euclidean: 93.31 	|
| parsbert-base-uncased-farstail            	| farstail    	| F1: 81.65,  Accuracy: 81.71                                                     	|
| bert-fa-base-uncased-farstail-mean-tokens 	| farstail    	| Accuracy: 56.45                                                                 	|


## How to use ( Applications )
| Application           	| Notebook                                                                                                                                                                                    	|
|-----------------------	|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| Semantic Search       	| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hooshvare/parsbert/blob/master/notebooks/Semantic_Search.ipynb)       	|
| Clustering               	| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hooshvare/parsbert/blob/master/notebooks/Clustering.ipynb)               	|
| Text Summarization    	| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hooshvare/parsbert/blob/master/notebooks/Text_Summarization.ipynb)    	|
| Information Retrieval 	| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hooshvare/parsbert/blob/master/notebooks/Information_Retrieval.ipynb) 	|
| Topic Modeling        	| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hooshvare/parsbert/blob/master/notebooks/Topic_Modeling.ipynb)        	|


## Model Releases
1.0.0: Hello World!

- [m3hrdadfi/bert-fa-base-uncased-wikinli-mean-tokens](https://huggingface.co/m3hrdadfi/bert-fa-base-uncased-wikinli-mean-tokens)
- [m3hrdadfi/bert-fa-base-uncased-wikinli](https://huggingface.co/m3hrdadfi/bert-fa-base-uncased-wikinli)
- [m3hrdadfi/bert-fa-base-uncased-wikitriplet-mean-tokens](https://huggingface.co/m3hrdadfi/bert-fa-base-uncased-wikitriplet-mean-tokens)
- [m3hrdadfi/bert-fa-base-uncased-farstail](https://huggingface.co/m3hrdadfi/bert-fa-base-uncased-farstail)
- [m3hrdadfi/bert-fa-base-uncased-farstail-mean-tokens](https://huggingface.co/m3hrdadfi/bert-fa-base-uncased-farstail-mean-tokens)
  
   
## Cite
Please cite this repository in publications as the following:

```markdown
@misc{SentenceTransformerWiki,
  author = {Mehrdad Farahani},
  title = {Sentence Embeddings with ParsBERT},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {https://github.com/m3hrdadfi/sentence-transformers},
}
```

## License
[Apache License 2.0](LICENSE)